# Import necessary libraries
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Example dataset (replace with your own dataset)
# Create a sample dataframe for illustration
data = {
    'Feature': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
    'Target': [1.1, 2.0, 2.9, 4.1, 5.0, 5.9, 6.8, 8.0, 9.1, 10.2]
}
df = pd.DataFrame(data)

# Define independent (X) and dependent (y) variables
X = df[['Feature']]
y = df['Target']

# Set random state
random_state = 0

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)

# Create an instance of LinearRegression
lr = LinearRegression()

# Train the linear regression model
lr.fit(X_train, y_train)

# Make predictions on the test set
y_pred = lr.predict(X_test)

# Evaluate the model
MSE = mean_squared_error(y_test, y_pred)
RMSE = np.sqrt(MSE)
R2 = r2_score(y_test, y_pred)

# Print results
print("Mean Squared Error (MSE):", MSE)
print("Root Mean Squared Error (RMSE):", RMSE)
print("R-squared (R²) Score:", R2)


Steps Explained:

Dataset Preparation: Replace the example data dictionary with your actual dataset.

Feature and Target Assignment: Adjust X and y to match your dataset's feature and target columns.

Model Splitting: Use train_test_split with an 80-20 split and random_state=0 for reproducibility.

Linear Regression Model: Instantiate and fit the model to the training data.

Predictions: Use predict() on X_test to generate predictions.

Evaluation Metrics:

MSE: Measures the average squared difference between the predicted and actual values.

RMSE: Square root of MSE, interpretable in the same units as the target variable.

R²: Explains the proportion of variance in the target variable captured by the model.
