

1. **Mean Squared Error (MSE):**
   ```python
   MSE = mean_squared_error(y_test, y_pred)
   ```
   - Calculates the average squared differences between the actual and predicted values. Lower values indicate a better fit.

2. **Root Mean Squared Error (RMSE):**
   ```python
   RMSE = np.sqrt(mean_squared_error(y_test, y_pred))
   ```
   - The square root of MSE, making it interpretable in the same units as the target variable.

3. **R-squared (R²):**
   ```python
   R2 = r2_score(y_test, y_pred)
   ```
   - Measures the proportion of the variance in the dependent variable that is predictable from the independent variable(s). R² values range from 0 to 1, where 1 indicates a perfect fit.

4. **Print Results:**
   ```python
   print('Mean Square Error:', MSE)
   print('Root Mean Square Error:', RMSE)
   print('R2:', R2)
   ```

### Full Code Block with Context:
Here’s how you integrate it into the full workflow:

```python
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np
import pandas as pd

# Example dataset
data = {
    'Feature': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
    'Target': [1.1, 2.0, 2.9, 4.1, 5.0, 5.9, 6.8, 8.0, 9.1, 10.2]
}
df = pd.DataFrame(data)

# Splitting data
X = df[['Feature']]
y = df['Target']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Training the model
lr = LinearRegression()
lr.fit(X_train, y_train)

# Making predictions
y_pred = lr.predict(X_test)

# Evaluation
MSE = mean_squared_error(y_test, y_pred)
RMSE = np.sqrt(MSE)
R2 = r2_score(y_test, y_pred)

# Display metrics
print('Mean Square Error:', MSE)
print('Root Mean Square Error:', RMSE)
print('R2:', R2)
```

This will give you:
- Mean Square Error
- Root Mean Square Error
- R² Score 

